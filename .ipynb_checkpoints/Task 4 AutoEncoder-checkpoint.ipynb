{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import losses\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, Reshape, UpSampling2D, Dense\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adadelta, SGD, Adam\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from scipy.misc import imresize\n",
    "from keras.layers import concatenate\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import np_utils\n",
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data from CSVs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 3, 3, 2, 2, 4, 2, 2, 4, 2, 3, 4, 2, 2]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_data = pd.read_csv(\"15features.csv\")\n",
    "training_data = pd.read_csv(\"seen-dataset/dataset_seen_training_siamese.csv\")\n",
    "validation_data = pd.read_csv(\"seen-dataset/dataset_seen_validation_siamese.csv\")\n",
    "\n",
    "training_data = training_data.drop('Unnamed: 0',1)\n",
    "validation_data = validation_data.drop('Unnamed: 0',1)\n",
    "\n",
    "train_path = 'seen-dataset/TrainingSet/'\n",
    "train_images = os.listdir(train_path)\n",
    "#print(len(train_images))\n",
    "val_path = 'seen-dataset/ValidationSet/'\n",
    "val_images = os.listdir(val_path)\n",
    "\n",
    "columns = features_data.columns\n",
    "\n",
    "\n",
    "\n",
    "#Get the unique no of values a given feature can take.\n",
    "features_values = []\n",
    "for i in columns[1:]:\n",
    "    #print(i)\n",
    "    features_values.append(features_data[i].unique().shape[0])\n",
    "features_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen(batch_size,image_path,list_of_writers, vshift = (-64,64) ,vis=False):\n",
    "    counter = 0\n",
    "    w_ids,ids,x,y,imagenames, feature_list = [],[],[],[],[],[]\n",
    "    while True:\n",
    "#         counter = 0\n",
    "        # for writer in unique_writers:\n",
    "        #     print(identitycounter*100/stop_at, end='\\r')\n",
    "        \n",
    "        writer_index = np.random.randint(0,len(list_of_writers))\n",
    "        \n",
    "#         for writer_index in writer_indexes:\n",
    "#             class_vectors = []\n",
    "#             features = None\n",
    "        imagename = list_of_writers[writer_index]\n",
    "#             print('-->',csv_data['imagename'][0],imagename)\n",
    "#             display(csv_data[csv_data['imagename']==imagename].values[0][1:])\n",
    "        features = features_data[features_data['imagename']==imagename].values\n",
    "        if len(features)==0:\n",
    "#             print('no features', imagename)\n",
    "            continue\n",
    "        features = features[0][1:]-1\n",
    "#             print(features)\n",
    "#             print(writer)\n",
    "#             writer_samples = list(images[images['image'].str.match(writer)]['image'])\n",
    "#             print('writer:',writer,', writer_samples:',writer_samples)\n",
    "#             if len(writer_samples) == 0:\n",
    "#                 continue\n",
    "#             writer_sample_index = np.random.randint(0,len(writer_samples))\n",
    "\n",
    "#             #     unique_writers_count[writer] = len(writer_samples)\n",
    "# #             print('writer_sample_index:',writer_sample_index)\n",
    "#             csv_writer = writer_samples[writer_sample_index][:5]\n",
    "\n",
    "\n",
    "        loaded_image = cv2.imread(os.path.join(image_path,imagename),0)\n",
    "        rand = np.random.randint(vshift[0],vshift[1])\n",
    "        loaded_image_shifted=np.roll(axis=0,a=loaded_image,shift=rand)\n",
    "\n",
    "        x.append(255.0-loaded_image_shifted.reshape((64,64,1)))\n",
    "        y.append(255.0-loaded_image.reshape((64,64,1)))\n",
    "        w_ids.append(imagename[:4])\n",
    "        imagenames.append(imagename)\n",
    "        ids.append(writer_index)\n",
    "        feature_list.append(features)\n",
    "#         print(imagename)\n",
    "        counter+=1\n",
    "#         print('counter:', counter, end='\\r')\n",
    "        if counter == batch_size:\n",
    "            counter=0\n",
    "            feature_list = np.array(feature_list)\n",
    "            feature_list = feature_list.transpose()\n",
    "            out_cat_features = []\n",
    "            for i in range(len(feature_list)):\n",
    "#                 print(feature_list[1])\n",
    "                out_cat_features.append(to_categorical(feature_list[i],num_classes=features_values[i]))\n",
    "            if vis== True:\n",
    "                yield np.array(x)/255.0,[np.array(w_ids),np.array(imagenames)]\n",
    "            else:\n",
    "                yield np.array(x)/255.0,out_cat_features\n",
    "            w_ids,ids,x,y,imagenames,feature_list =[], [],[], [],[],[]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seen Dataset AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'saved-model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1804460b799e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved-model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;31m#autoencoder.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'saved-model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(64, 64, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same', name='encoded')(x)\n",
    "# encoded = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# encoder = Model(input_img, encoded)\n",
    "# encoder.summary()\n",
    "# print(encoded.shape)\n",
    "# encoded = Flatten()(x)\n",
    "# encoded = Dense(8*8*8)(encoded)\n",
    "# # model = Model(input_img,encoded)\n",
    "# # print(model.summary())\n",
    "# # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "# r = Reshape(target_shape=(8,8,8))(encoded)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='output')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "autoencoder.load_weights('saved-model.h5')\n",
    "#autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating non-trainable encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(autoencoder.input,autoencoder.get_layer('encoded').output)\n",
    "for layer in encoder.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating individual Neural Networks for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = encoder.get_layer('encoded').output\n",
    "out_dense_layer=[]\n",
    "for i in range(1,len(features_values)+1):\n",
    "    out_dense_layer.append(Dense(features_values[i-1] , activation='softmax', name = 'out_feature_'+str(i))(Dense(128 , activation='relu', name = 'dense_layer_'+str(i))(Flatten()((dense_layer)))))\n",
    "\n",
    "human_features = Model(inputs=encoder.input, outputs=out_dense_layer)\n",
    "human_features.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVG(model_to_dot(human_features, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {}\n",
    "lossWeights = {}\n",
    "for i in range(1,16):\n",
    "    losses[\"out_feature_\"+str(i)] = \"categorical_crossentropy\"\n",
    "    lossWeights[\"out_feature_\"+str(i)] = 1.0\n",
    "#print(losses)\n",
    "#print(lossWeights)\n",
    "\n",
    "EPOCHS = 500\n",
    "INIT_LR = 0.0001\n",
    "batch_size = 256\n",
    "es = EarlyStopping(patience=10000, monitor='val_loss', min_delta=0.0005, mode='auto')\n",
    "opt = SGD(lr=INIT_LR, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "#human_features.compile(optimizer=opt, loss=losses, loss_weights=lossWeights,metrics=[\"accuracy\"])\n",
    "human_features.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "#human_features.summary()\n",
    "training_datagen = datagen(batch_size,image_path=train_path,vshift=(-10,10),list_of_writers=train_images)\n",
    "validation_datagen = datagen(batch_size,image_path=val_path,vshift=(-10,10), list_of_writers=val_images)\n",
    "hist = human_features.fit_generator(training_datagen\n",
    "                                    , epochs=EPOCHS\n",
    "                                    , steps_per_epoch = 1#len(train_images)//batch_size\n",
    "                                    , validation_data = validation_datagen\n",
    "                                    , validation_steps = 1#len(train_images)//batch_size\n",
    "                                    , verbose = 3)\n",
    "human_features.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000 Epochs and Learning Rate: 0.0001 Optimizer=SGD => Val_Loss ~ 10\n",
    "# 5000 Epochs and Learning Rate: 0.0001 Optimizer=SGD => Val_Loss ~ 10\n",
    "# 500 Epochs and Learning Rate 0.0001 Optimizer=SGD => Val_loss ~ 10\n",
    "# 500 Epochs and Learning Rate 0.001 Optimizer=SGD => Val_loss ~ 10\n",
    "# 500 Epochs and Learning Rate 0.01 Optimizer=SGD => Val_loss ~ 10\n",
    "\n",
    "df_hist = pd.DataFrame(hist.history)\n",
    "df_hist.plot(subplots=True, figsize=(15,100))\n",
    "print(df_hist['val_loss'].min())\n",
    "#print(df_hist['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#human_features.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx,vo=next(validation_datagen)\n",
    "real_rows = []\n",
    "pred_rows = []\n",
    "for i in range(64):\n",
    "    real=[]\n",
    "    for f in range(15):\n",
    "        real.append(np.argmax(vo[f][i])+1)\n",
    "        real_rows.append(real)\n",
    "    \n",
    "    f_probs = human_features.predict(np.expand_dims(vx[i],0))\n",
    "    pred=[]\n",
    "    for prob in f_probs:\n",
    "        pred.append(np.argmax(prob[0])+1)\n",
    "        pred_rows.append(pred)\n",
    "counter = 0\n",
    " \n",
    "\n",
    "#print(\"Accuracy: \"+str(counter/len(real_rows)))\n",
    "#display(real_rows[234])\n",
    "#display(pred_rows[234:240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_features.load_weights('human_features_weights_v2.h5')\n",
    "# human_features.load_weights('weights/15-Multitask-FrozenEncoder-unseen_v1.h5')\n",
    "vx,vo=next(validation_datagen)\n",
    "# print(len(vo))\n",
    "fig = plt.figure(figsize=(80,200))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=1.51, wspace=0.05)\n",
    "for i in range(64):\n",
    "#     print(i, '\\nPredicted:')\n",
    "    \n",
    "    real=''\n",
    "    for f in range(15):\n",
    "#         print(vo[i][f])\n",
    "        real+=str(np.argmax(vo[f][i])+1)+','\n",
    "    \n",
    "    f_probs = human_features.predict(np.expand_dims(vx[i],0))\n",
    "#     print(f_probs)\n",
    "    pred=''\n",
    "    for prob in f_probs:\n",
    "#         print(prob)\n",
    "        pred+=str(np.argmax(prob[0])+1)+','\n",
    "    \n",
    "    ax = fig.add_subplot(64, 1, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(vx[i].reshape((64,64)))\n",
    "    ax.set_title('real:'+real+'\\n pred:'+pred)\n",
    "#     print('\\n----------')\n",
    "#     print('True:')\n",
    "#     for op in o:\n",
    "#         print(np.argmax(op[i]),end=',')\n",
    "        \n",
    "#     print('\\n++++++',i,'++++++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_g = datagen(batch_size,image_path=val_path,vshift=(-10,10), list_of_writers=val_images)\n",
    "vx,vy = next(test_g)\n",
    "\n",
    "print(vx.shape,vy[0].shape)\n",
    "py = autoencoder.predict(vx[:10])\n",
    "f,ax = plt.subplots(len(vx[:10]),2)\n",
    "f.subplots_adjust(hspace = .00, wspace=.05)\n",
    "f.set_size_inches(5,len(vx[:10])*3)\n",
    "ax[0,0].set_title('TRUE')\n",
    "ax[0,1].set_title('PRED')\n",
    "for i in range(len(vx[:10])):\n",
    "#     print(vy[0][i], vy[1][i])\n",
    "    ax[i,0].imshow(vx[i].reshape((64,64)))\n",
    "    ax[i,0].axis('off')\n",
    "    \n",
    "    ax[i,1].imshow(py[i].reshape((64,64)))\n",
    "    ax[i,1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
